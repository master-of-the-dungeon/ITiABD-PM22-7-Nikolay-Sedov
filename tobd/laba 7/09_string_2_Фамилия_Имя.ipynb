{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvK2TwmdcsKx"
   },
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4VMM1dCcsK6"
   },
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRLm0KHScsK7"
   },
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XsA5IzfqcsK8",
    "ExecuteTime": {
     "start_time": "2023-05-17T12:06:32.897298Z",
     "end_time": "2023-05-17T12:06:32.910204Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRZ4--DxcsK-"
   },
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9Sp6REWCcsK_"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f:\n\u001B[0;32m      5\u001B[0m         words_list\u001B[38;5;241m.\u001B[39mextend(line\u001B[38;5;241m.\u001B[39msplit())\n\u001B[1;32m----> 7\u001B[0m morph \u001B[38;5;241m=\u001B[39m \u001B[43mMorphAnalyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m words_list \u001B[38;5;241m=\u001B[39m [morph\u001B[38;5;241m.\u001B[39mparse(word)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mnormal_form \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m words_list]\n\u001B[0;32m     10\u001B[0m vectorizer \u001B[38;5;241m=\u001B[39m CountVectorizer(analyzer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchar\u001B[39m\u001B[38;5;124m'\u001B[39m, ngram_range\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:224\u001B[0m, in \u001B[0;36mMorphAnalyzer.__init__\u001B[1;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result_type_orig \u001B[38;5;241m=\u001B[39m result_type\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_char_substitutes(char_substitutes)\n\u001B[1;32m--> 224\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_units\u001B[49m\u001B[43m(\u001B[49m\u001B[43munits\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:235\u001B[0m, in \u001B[0;36mMorphAnalyzer._init_units\u001B[1;34m(self, units_unbound)\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(item, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m unit \u001B[38;5;129;01min\u001B[39;00m item[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m--> 235\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_units\u001B[38;5;241m.\u001B[39mappend((\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_unit\u001B[49m\u001B[43m(\u001B[49m\u001B[43munit\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28;01mFalse\u001B[39;00m))\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_units\u001B[38;5;241m.\u001B[39mappend((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_unit(item[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]), \u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:246\u001B[0m, in \u001B[0;36mMorphAnalyzer._bound_unit\u001B[1;34m(self, unit)\u001B[0m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_bound_unit\u001B[39m(\u001B[38;5;28mself\u001B[39m, unit):\n\u001B[1;32m--> 246\u001B[0m     unit \u001B[38;5;241m=\u001B[39m \u001B[43munit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    247\u001B[0m     unit\u001B[38;5;241m.\u001B[39minit(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m unit\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:35\u001B[0m, in \u001B[0;36mBaseAnalyzerUnit.clone\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclone\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:76\u001B[0m, in \u001B[0;36mBaseAnalyzerUnit._get_params\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_params\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     74\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001B[39;00m\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mdict\u001B[39m(\n\u001B[1;32m---> 76\u001B[0m         (key, \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, \u001B[38;5;28;01mNone\u001B[39;00m)) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_param_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:70\u001B[0m, in \u001B[0;36mBaseAnalyzerUnit._get_param_names\u001B[1;34m(cls)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m:\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m []\n\u001B[1;32m---> 70\u001B[0m args, varargs, kw, default \u001B[38;5;241m=\u001B[39m \u001B[43minspect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetargspec\u001B[49m(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m)\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(args[\u001B[38;5;241m1\u001B[39m:])\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "words_list = []\n",
    "\n",
    "with open('litw-win.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        words_list.extend(line.split())\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "words_list = [morph.parse(word)[0].normal_form for word in words_list]\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X = vectorizer.fit_transform(words_list)\n",
    "\n",
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''\n",
    "\n",
    "words = text.split()\n",
    "corrected_words = []\n",
    "\n",
    "for word in words:\n",
    "    word = morph.parse(word)[0].normal_form\n",
    "    if word not in words_list:\n",
    "        Y = vectorizer.transform([word])\n",
    "        distances = ((X - Y) ** 2).sum(axis=1)\n",
    "        corrected_word = words_list[np.argmin(distances)]\n",
    "        corrected_words.append(corrected_word)\n",
    "    else:\n",
    "        corrected_words.append(word)\n",
    "\n",
    "corrected_text = ' '.join(corrected_words)\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yULsGQpacsLA"
   },
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SwcrtwRcsLA"
   },
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tio9mRCLcsLB"
   },
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At0bv3jjcsLC"
   },
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9b_6xLbcsLC"
   },
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckulhf2ZcsLD"
   },
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfHlU4yOcsLD"
   },
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEGqbapEcsLE"
   },
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAGgb9ducsLE"
   },
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xEkpF6VcsLF"
   },
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NT5J_hxvcsLG"
   },
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHM71XurcsLG"
   },
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5RPLxskcsLH"
   },
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K862z3tTcsLH"
   },
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSxhPS-scsLI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
